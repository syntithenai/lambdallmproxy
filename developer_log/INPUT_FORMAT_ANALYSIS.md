# Input Format Analysis: Messages Sent TO gpt-oss Models

**Date**: November 1, 2025  
**Status**: ‚úÖ INPUT FORMAT CORRECT - Using OpenAI Format  
**Context**: Phase 2 follow-up - Verifying message format sent TO LLMs

---

## Executive Summary

**Good News**: The input format (messages sent TO gpt-oss models) is **CORRECT**. We're sending standard OpenAI-compatible messages with proper `tool_calls` arrays and `role: tool` messages for results.

**The Problem**: gpt-oss models were trained on **mixed data** (OpenAI + Claude/Anthropic formats), so even when receiving correct OpenAI-format input, they sometimes respond with Claude-style XML syntax.

**The Solution**: Our Phase 2 implementation (output cleaning) is the correct approach. We can't change the model's training data, but we can clean their output.

---

## Current Input Format (VERIFIED CORRECT ‚úÖ)

### For Groq Provider (including gpt-oss models)

**Location**: `src/llm_tools_adapter.js` Lines 406-422

```javascript
if (isGroqModel(normalizedModel)) {
    const hostname = 'api.groq.com';
    const path = '/openai/v1/chat/completions';
    const messages = (input || []).map(block => {
      if (block.type === 'function_call_output') {
        return { role: 'tool', content: block.output, tool_call_id: block.call_id };
      }
      if (block.role) {
        const message = { role: block.role, content: block.content };
        // Preserve tool_calls for assistant messages
        if (block.tool_calls) {
          message.tool_calls = block.tool_calls;
        }
        return message;
      }
      return null;
    }).filter(Boolean);
```

**Format Sent**:
```json
{
  "model": "openai/gpt-oss-120b",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant..."
    },
    {
      "role": "user",
      "content": "Search for AI news"
    },
    {
      "role": "assistant",
      "content": "",
      "tool_calls": [
        {
          "id": "call_abc123",
          "type": "function",
          "function": {
            "name": "search_web",
            "arguments": "{\"query\":\"AI news\"}"
          }
        }
      ]
    },
    {
      "role": "tool",
      "content": "{\"results\": [...]}",
      "tool_call_id": "call_abc123"
    }
  ],
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "search_web",
        "description": "Search the web...",
        "parameters": {...}
      }
    }
  ],
  "tool_choice": "auto"
}
```

This is **100% correct OpenAI format**. ‚úÖ

---

## System Prompt Approach (Currently Used)

**Location**: `src/lambda_search_llm_handler.js` Line 4 (part of dynamicSystemPrompt)

**Current Approach**:
```javascript
'CRITICAL: Do NOT include XML tags, JSON objects, or function call syntax in your text responses. 
NEVER write things like <execute_javascript>{"code": "..."}</execute_javascript> or 
<function=search_web> or <function=execute_javascript> in your response. 
This API uses OpenAI function calling format, NOT Anthropic/Claude syntax. 
Tool calls happen automatically through the API.'
```

**Assessment**: 
- ‚ö†Ô∏è **Partially Effective**: Reduces frequency of Claude syntax but doesn't eliminate it
- ‚ùå **Not Reliable**: LLMs are not 100% reliable at following format constraints
- ‚úÖ **Should Keep**: No harm in keeping, provides additional guidance

---

## Why gpt-oss Models Generate Claude Syntax

### Root Cause Analysis

**1. Mixed Training Data**
- gpt-oss models were trained on datasets including both:
  - OpenAI API examples (with `tool_calls` arrays)
  - Claude/Anthropic API examples (with XML-style function syntax)
- The model has learned both patterns and sometimes defaults to Claude style

**2. Token Probability**
- When the model is uncertain, it may sample from the Claude-style tokens
- This happens even when:
  - Input is correct OpenAI format
  - System prompt says not to use Claude syntax
  - Tools are properly defined in OpenAI format

**3. Context Length and Complexity**
- Longer conversations may increase likelihood of format confusion
- Complex tool chains may trigger Claude-style output
- The model "forgets" the format constraint as context grows

---

## Why Output Cleaning is the Right Solution

### Option 1: Change Input Format (‚ùå Not Viable)

**What we could try**:
- Send Claude-style format TO the model
- Hope it responds in Claude style consistently
- Convert Claude responses to OpenAI format

**Why this fails**:
- Groq's API is OpenAI-compatible, not Claude-compatible
- We'd need to implement a full Claude message format
- Other Groq models expect OpenAI format
- Would break existing functionality

### Option 2: Use Different Models (‚ö†Ô∏è Partial Solution)

**What we could do**:
- Disable gpt-oss models
- Only use models that reliably follow OpenAI format

**Why this is limiting**:
- gpt-oss models are free on Groq
- They're fast (20B: 1000 tps, 120B: 500 tps)
- Users may prefer them for cost/performance

### Option 3: Output Cleaning (‚úÖ Current Approach - BEST)

**What we implemented** (Phase 2):
- Send correct OpenAI format to model (keep current behavior)
- Clean Claude-style syntax from responses
- Works for streaming and non-streaming
- Transparent to users

**Why this is best**:
- ‚úÖ No changes needed to input format
- ‚úÖ Works with all Groq models
- ‚úÖ Zero breaking changes
- ‚úÖ Handles edge cases gracefully
- ‚úÖ Can be extended to other models if needed

---

## Input Format Best Practices (Already Implemented ‚úÖ)

### 1. Message Structure (Lines 406-422)

**‚úÖ Correct**: Using standard OpenAI message roles
```javascript
{ role: 'system', content: '...' }
{ role: 'user', content: '...' }
{ role: 'assistant', content: '...', tool_calls: [...] }
{ role: 'tool', content: '...', tool_call_id: '...' }
```

**‚ùå Wrong** (Claude format - NOT used):
```xml
<user>Search for AI news</user>
<function_calls>
  <invoke>
    <tool_name>search_web</tool_name>
    <parameters>{"query": "AI news"}</parameters>
  </invoke>
</function_calls>
```

### 2. Tool Definitions (Lines 428-431)

**‚úÖ Correct**: OpenAI tools format
```javascript
{
  tools: [
    {
      type: 'function',
      function: {
        name: 'search_web',
        description: '...',
        parameters: { type: 'object', properties: {...} }
      }
    }
  ],
  tool_choice: 'auto'
}
```

### 3. Tool Results (Lines 408-410)

**‚úÖ Correct**: Using `role: tool` with `tool_call_id`
```javascript
{
  role: 'tool',
  content: '{"results": [...]}',
  tool_call_id: 'call_abc123'
}
```

---

## Recommendations

### Keep Current Implementation ‚úÖ

**Input Side** (No changes needed):
- ‚úÖ Continue sending OpenAI-format messages
- ‚úÖ Keep system prompt warning about Claude syntax
- ‚úÖ Use standard tool definitions

**Output Side** (Phase 2 implementation):
- ‚úÖ Continue using output cleaning for gpt-oss models
- ‚úÖ Monitor for new patterns and update regex if needed
- ‚úÖ Test with real usage to verify effectiveness

### Optional Enhancement: Improved System Prompt

**Current**:
```
CRITICAL: Do NOT include XML tags, JSON objects, or function call syntax...
```

**Enhanced** (Optional):
```
CRITICAL RESPONSE FORMAT:
- Write your response as plain text only
- Do NOT use XML tags like <function=name> or <execute_javascript>
- Do NOT include JSON in your text (e.g., {"code": "..."})
- Tool calls are handled automatically by the API
- You don't need to write function call syntax - just respond naturally

Examples of what NOT to do:
‚ùå <function=search_web>
‚ùå <execute_javascript>{"code": "..."}</execute_javascript>
‚ùå <search_web query="..." />

The system will automatically handle tool calling for you.
```

**Impact**: May slightly improve compliance, but output cleaning is still required as LLMs are not 100% reliable.

---

## Testing Verification

### Test 1: Verify Input Format (Manual Check)

**How to test**:
1. Add logging before sending request to Groq:
```javascript
console.log('üì§ Sending to Groq:', JSON.stringify(payload, null, 2));
```

2. Send a request with tools enabled
3. Check logs for proper format

**Expected**:
- Messages array with correct roles
- Tools array with OpenAI format
- No Claude-style XML in input

### Test 2: Verify Output Cleaning Works

**How to test**:
1. Use gpt-oss-120b model
2. Ask it to search or execute JavaScript
3. Check UI response for Claude syntax

**Expected**:
- No `<function=...>` tags in UI
- No XML-style function calls visible
- Clean, readable text only

### Test 3: Compare with Standard Models

**How to test**:
1. Same prompt with `groq:llama-3.1-70b-versatile` (no cleaning)
2. Same prompt with `groq:openai/gpt-oss-120b` (with cleaning)
3. Compare output quality

**Expected**:
- Both should produce clean output
- gpt-oss may have had Claude syntax cleaned
- No functional difference for users

---

## Conclusion

**Input Format**: ‚úÖ **CORRECT - No changes needed**
- We're already sending proper OpenAI-format messages
- Tools are defined correctly
- Message structure follows OpenAI API spec

**Output Format**: ‚úÖ **HANDLED - Phase 2 implementation**
- Automatic cleaning of Claude syntax
- Works for streaming and non-streaming
- Transparent to users

**Next Steps**:
1. Keep current input format (no changes)
2. Deploy Phase 2 output cleaning (ready)
3. Test with real gpt-oss model usage
4. Optionally: Enhance system prompt for clarity
5. Monitor and adjust cleaning patterns if needed

**Status**: ‚úÖ SYSTEM DESIGN CORRECT - Input + Output both handled properly
