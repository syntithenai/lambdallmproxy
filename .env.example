# ================================================================
# LLM Proxy Environment Configuration (Example)
# ================================================================
# Copy this file to .env and configure with your actual values
# ================================================================

# ----------------------------------------------------------------
# AUTHENTICATION & AUTHORIZATION
# ----------------------------------------------------------------

# Comma-separated list of Google account emails allowed to use 
# server-side API keys (environment providers)
# Users not in this list can only use their own client-provided keys
# Leave empty to require all users to provide their own keys
ALLOWED_EMAILS=user1@example.com,user2@example.com

# Optional access secret for legacy authentication
# Used in lambda_search_llm_handler.js for basic auth
# Leave empty to disable legacy auth
ACCESS_SECRET=your-secret-here

# ----------------------------------------------------------------
# PROVIDER CREDENTIALS (New Format - RECOMMENDED)
# ----------------------------------------------------------------
# Configure API providers using indexed environment variables
# Format: LLAMDA_LLM_PROXY_PROVIDER_<FIELD>_<INDEX>
# 
# Required fields:
#   TYPE_N   - Provider type (openai, groq-free, gemini-free, etc.)
#   KEY_N    - API key for the provider
# 
# Optional fields:
#   ENDPOINT_N    - Custom API endpoint (for openai-compatible)
#   MODEL_N       - Default model name (for openai-compatible)
#   RATE_LIMIT_N  - Rate limit in TPM (for openai-compatible)
# 
# These providers are ONLY available to authorized users (in ALLOWED_EMAILS)
# ----------------------------------------------------------------

# Example Provider 0: OpenAI
# LLAMDA_LLM_PROXY_PROVIDER_TYPE_0=openai
# LLAMDA_LLM_PROXY_PROVIDER_KEY_0=sk-proj-your-openai-key-here

# Example Provider 1: Groq Free Tier
# LLAMDA_LLM_PROXY_PROVIDER_TYPE_1=groq-free
# LLAMDA_LLM_PROXY_PROVIDER_KEY_1=gsk_your-groq-key-here

# Example Provider 2: Gemini Free Tier (NOT YET IMPLEMENTED)
# LLAMDA_LLM_PROXY_PROVIDER_TYPE_2=gemini-free
# LLAMDA_LLM_PROXY_PROVIDER_KEY_2=your-gemini-key-here

# Example Provider 3: Custom OpenAI-Compatible Provider
# LLAMDA_LLM_PROXY_PROVIDER_TYPE_3=openai-compatible
# LLAMDA_LLM_PROXY_PROVIDER_KEY_3=your-key-here
# LLAMDA_LLM_PROXY_PROVIDER_ENDPOINT_3=https://api.custom-provider.com/v1/chat/completions
# LLAMDA_LLM_PROXY_PROVIDER_MODEL_3=custom-model-name
# LLAMDA_LLM_PROXY_PROVIDER_RATE_LIMIT_3=10000

# ----------------------------------------------------------------
# LEGACY PROVIDER KEYS (Deprecated)
# ----------------------------------------------------------------
# These are still used as fallbacks in some parts of the codebase
# Use new format above instead
# ----------------------------------------------------------------

# OPENAI_API_KEY=sk-your-openai-key-here
# GROQ_API_KEY=gsk_your-groq-key-here
# OPENAI_API_BASE=https://api.openai.com

# ----------------------------------------------------------------
# TOOL EXECUTION CONFIGURATION
# ----------------------------------------------------------------

# Maximum number of tool call iterations before stopping
# Default: 15
MAX_TOOL_ITERATIONS=10

# Reasoning effort level for reasoning models (low, medium, high)
# Default: medium
REASONING_EFFORT=medium

# ----------------------------------------------------------------
# MODEL CONFIGURATION (Optional)
# ----------------------------------------------------------------

# Comma-separated list of Groq models that support reasoning
# GROQ_REASONING_MODELS=

# Default Groq model for tool execution fallback
# GROQ_MODEL=llama-3.1-8b-instant

# Default OpenAI model for tool execution fallback
# OPENAI_MODEL=gpt-4o-mini

# ----------------------------------------------------------------
# SYSTEM PROMPTS (Optional Overrides)
# ----------------------------------------------------------------

# Main system prompt for search-enabled queries
# SYSTEM_PROMPT_SEARCH=You are a highly knowledgeable AI assistant...

# System prompt for search result analysis
# SYSTEM_PROMPT_DIGEST_ANALYST=You are a thorough research analyst...

# ----------------------------------------------------------------
# TEMPLATE OVERRIDES (Optional)
# ----------------------------------------------------------------

# Final response template for multi-search synthesis
# FINAL_TEMPLATE=Based on comprehensive multi-search research...

# ================================================================
# DEPLOYMENT NOTES
# ================================================================
# 
# AWS Lambda:
# - Set environment variables in Lambda console
# - Do not include this file in deployment
# - Use AWS Secrets Manager for sensitive keys
# 
# Local Development:
# - Copy this file to .env
# - Fill in your actual API keys
# - Never commit .env to version control
# 
# CI/CD:
# - Use environment-specific secrets
# - Inject variables at deployment time
# - Rotate keys regularly
# 
# ================================================================
