# ================================================================
# Lambda LLM Proxy - Environment Configuration Example
# ================================================================
# Copy this file to .env and fill in your actual values
# ================================================================

# ----------------------------------------------------------------
# AUTHENTICATION & AUTHORIZATION
# ----------------------------------------------------------------

# Comma-separated list of authorized Google account emails
ALLOWED_EMAILS=user1@example.com,user2@example.com

# Optional legacy access secret for basic authentication
ACCESS_SECRET=your-secret-here

# ----------------------------------------------------------------
# GOOGLE OAUTH CONFIGURATION (for YouTube Transcripts)
# ----------------------------------------------------------------

# Google OAuth 2.0 credentials for YouTube Data API v3
# Get these from: https://console.cloud.google.com/apis/credentials
GOOGLE_CLIENT_ID=your-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=GOCSPX-your-client-secret
OAUTH_REDIRECT_URI=https://your-lambda-url.lambda-url.us-east-1.on.aws/oauth/callback

# Webshare proxy configuration (for YouTube transcript fetching from AWS)
# Required because YouTube blocks AWS/cloud provider IPs
# Sign up at: https://www.webshare.io (purchase "Residential" proxies)
# Get credentials from: https://dashboard.webshare.io/proxy/settings
# Use the "Proxy Username" and "Proxy Password" values
WEBSHARE_PROXY_USERNAME=your-proxy-username
WEBSHARE_PROXY_PASSWORD=your-proxy-password

# ----------------------------------------------------------------
# PROVIDER CONFIGURATION (New Format - REQUIRED)
# ----------------------------------------------------------------
# Configure multiple API providers using indexed environment variables
# Format: LLAMDA_LLM_PROXY_PROVIDER_<FIELD>_<INDEX>
#
# Required fields per provider:
#   TYPE_N   - Provider type (openai, groq-free, gemini-free, openai-compatible)
#   KEY_N    - API key for the provider
#
# Optional fields:
#   ENDPOINT_N    - Custom API endpoint (for openai-compatible providers)
#   MODEL_N       - Default model name (for openai-compatible providers)
#   RATE_LIMIT_N  - Rate limit in tokens per minute (for openai-compatible)
#
# These providers are ONLY available to authorized users (in ALLOWED_EMAILS)
#
# Get API keys from:
#   - OpenAI: https://platform.openai.com/api-keys
#   - Groq: https://console.groq.com/keys
#   - Gemini: https://makersuite.google.com/app/apikey
# ----------------------------------------------------------------

# Provider 0: Groq Free Tier (example)
LLAMDA_LLM_PROXY_PROVIDER_TYPE_0=groq-free
LLAMDA_LLM_PROXY_PROVIDER_KEY_0=gsk_your-groq-key-here

# Provider 1: OpenAI (example)
LLAMDA_LLM_PROXY_PROVIDER_TYPE_1=openai
LLAMDA_LLM_PROXY_PROVIDER_KEY_1=sk-proj-your-openai-key-here

# Provider 2: Gemini Free Tier (example)
LLAMDA_LLM_PROXY_PROVIDER_TYPE_2=gemini-free
LLAMDA_LLM_PROXY_PROVIDER_KEY_2=AIza-your-gemini-key-here

# Provider 3: Custom OpenAI-compatible endpoint (example - optional)
# LLAMDA_LLM_PROXY_PROVIDER_TYPE_3=openai-compatible
# LLAMDA_LLM_PROXY_PROVIDER_KEY_3=your-api-key
# LLAMDA_LLM_PROXY_PROVIDER_ENDPOINT_3=https://api.your-provider.com/v1
# LLAMDA_LLM_PROXY_PROVIDER_MODEL_3=your-model-name
# LLAMDA_LLM_PROXY_PROVIDER_RATE_LIMIT_3=100000

# ----------------------------------------------------------------
# TOOL CONFIGURATION
# ----------------------------------------------------------------

# Maximum number of tool call iterations before stopping (default: 15)
MAX_TOOL_ITERATIONS=10

# Disable YouTube Whisper transcription (does NOT affect YouTube API transcripts via OAuth)
# Set to 'true' to disable using Whisper for YouTube video transcription
# When true: YouTube videos can ONLY be transcribed via YouTube API (requires OAuth)
# When false: YouTube videos can use BOTH Whisper AND YouTube API transcription
# NOTE: YouTube SEARCH always works regardless of this setting
# Other media types (direct audio/video URLs) always use Whisper regardless of this setting
DISABLE_YOUTUBE_TRANSCRIPTION=false

# Media download timeout in milliseconds (default: 30000 = 30 seconds)
MEDIA_DOWNLOAD_TIMEOUT=30000

# ----------------------------------------------------------------
# CONTENT MODERATION / GUARDRAILS
# ----------------------------------------------------------------

# Enable content guardrails (input and output filtering)
# When enabled, ALL requests are filtered before processing
# and ALL responses are filtered before returning to user
# Default: false (disabled)
ENABLE_GUARDRAILS=false

# Guardrail provider (must be a configured provider with API key)
# Options: openai, anthropic, groq, groq-free, gemini, gemini-free, together
# This provider MUST have an API key configured (via indexed format or legacy env vars)
# Recommended: Use fast, cost-effective models
GUARDRAIL_PROVIDER=groq-free

# Model for filtering user input prompts
# Should be fast and cost-effective (e.g., gpt-4o-mini, claude-3-haiku, llama-3.1-8b-instant)
# Recommended: Models with strong content policy adherence
# Groq free: llama-3.1-8b-instant, llama-3.2-3b-preview
# OpenAI: gpt-4o-mini
# Anthropic: claude-3-haiku-20240307
GUARDRAIL_INPUT_MODEL=llama-3.1-8b-instant

# Model for filtering LLM output responses
# Can be same as input model or different
GUARDRAIL_OUTPUT_MODEL=llama-3.1-8b-instant

# Guardrail strictness level (optional, future enhancement)
# Options: strict, moderate, permissive
# Default: moderate
# GUARDRAIL_STRICTNESS=moderate

# ----------------------------------------------------------------
# WEB SCRAPING CONFIGURATION
# ----------------------------------------------------------------

# Puppeteer Lambda function ARN (for JavaScript-rendered pages)
# When set: Direct scraping tries first, falls back to Puppeteer Lambda if needed
# When not set: Only direct scraping is used (Tavily or DuckDuckGo with proxy)
# 
# Setup instructions:
#   1. Run: ./scripts/setup-puppeteer-function.sh
#   2. Run: ./scripts/deploy-puppeteer-lambda.sh
#   3. Run: ./scripts/setup-main-lambda-permissions.sh
#   4. Copy the ARN from the output and set it here
# 
# Example: PUPPETEER_LAMBDA_ARN=arn:aws:lambda:us-east-1:123456789012:function:llmproxy-puppeteer
PUPPETEER_LAMBDA_ARN=

# Enable/disable Puppeteer fallback (default: true)
# When true: Falls back to Puppeteer Lambda if direct scraping fails
# When false: Only direct scraping is attempted
USE_PUPPETEER=true

# ----------------------------------------------------------------
# MODEL CONFIGURATION
# ----------------------------------------------------------------

# Default Groq model for tool execution fallback
GROQ_MODEL=llama-3.1-8b-instant

# Default OpenAI model for tool execution fallback
# OPENAI_MODEL=gpt-4o-mini

# Comma-separated list of Groq models that support reasoning
# GROQ_REASONING_MODELS=llama-3.3-70b-versatile

# Reasoning effort level for reasoning models: low, medium, or high
REASONING_EFFORT=medium

# Custom OpenAI API base URL (for self-hosted or proxy endpoints)
# OPENAI_API_BASE=https://api.openai.com

# ----------------------------------------------------------------
# SYSTEM PROMPTS & TEMPLATES (Optional Overrides)
# ----------------------------------------------------------------
# These have sensible defaults in the code. Only set if you need custom behavior.

# Main system prompt for search-enabled queries
# SYSTEM_PROMPT_SEARCH=You are a highly knowledgeable AI assistant with access to powerful research and computational tools...

# System prompt for search result analysis
# SYSTEM_PROMPT_DIGEST_ANALYST=You are a thorough research analyst that extracts comprehensive information...

# Final response template for multi-search synthesis
# FINAL_TEMPLATE=Based on comprehensive multi-search research, provide the most complete answer...

# ----------------------------------------------------------------
# IMAGE GENERATION PROVIDERS (Optional)
# ----------------------------------------------------------------
# Configure API keys for image generation providers
# At least one provider must be configured for image generation to work

# OpenAI DALL-E (DALL-E 2 and DALL-E 3)
# Get API key from: https://platform.openai.com/api-keys
# Pricing: DALL-E 3: $0.040-0.120/image, DALL-E 2: $0.016-0.020/image
OPENAI_API_KEY=sk-your-openai-api-key-here

# Together AI (Stable Diffusion models)
# Get API key from: https://api.together.xyz/settings/api-keys
# Pricing: $0.001-0.003/image (more affordable than DALL-E)
TOGETHER_API_KEY=your-together-api-key-here

# Replicate (Various Stable Diffusion models)
# Get API token from: https://replicate.com/account/api-tokens
# Pricing: ~$0.0018-0.0025/image (pay-per-use, billed by compute time)
REPLICATE_API_TOKEN=r8_your-replicate-token-here

# Google Gemini/Imagen (Not yet available)
# Note: Google has not released public API for image generation
# This is reserved for future compatibility
# GEMINI_API_KEY=your-gemini-api-key-here

# ----------------------------------------------------------------
# IMAGE GENERATION FEATURE FLAGS (Optional)
# ----------------------------------------------------------------
# Enable/disable specific providers for image generation
# Default: true if API key exists, false otherwise

ENABLE_IMAGE_GENERATION_OPENAI=true
ENABLE_IMAGE_GENERATION_TOGETHER=true
ENABLE_IMAGE_GENERATION_REPLICATE=true
ENABLE_IMAGE_GENERATION_GEMINI=false

# ----------------------------------------------------------------
# IMAGE GENERATION CIRCUIT BREAKER (Optional)
# ----------------------------------------------------------------
# Circuit breaker prevents repeated calls to failing providers
# After FAILURE_THRESHOLD failures in TIMEOUT_MS, provider is disabled
# Provider automatically retries after TIMEOUT_MS (half-open state)

# Number of failures before opening circuit (default: 5)
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5

# Time window for failure tracking in milliseconds (default: 600000 = 10 minutes)
CIRCUIT_BREAKER_TIMEOUT_MS=600000

# ----------------------------------------------------------------
# GOOGLE SHEETS LOGGING (Optional)
# ----------------------------------------------------------------
# Enable automatic logging of LLM API requests to Google Sheets
# See GOOGLE_SHEETS_LOGGING_SETUP.md for detailed setup instructions
# Leave these unset to disable logging

# Your Google Sheet ID (from the spreadsheet URL)
# Example: https://docs.google.com/spreadsheets/d/1a2b3c4d5e6f7g8h9i0/edit
#                                                   ^^^^^^^^^^^^^^^^^^^
# GOOGLE_SHEETS_LOG_SPREADSHEET_ID=1a2b3c4d5e6f7g8h9i0

# Service account email (from the JSON key file)
# GOOGLE_SHEETS_SERVICE_ACCOUNT_EMAIL=llm-logger@your-project.iam.gserviceaccount.com

# Service account private key (from the JSON key file)
# IMPORTANT: Must include full key with -----BEGIN/END PRIVATE KEY----- markers
# Use \\n for newlines (double backslash), wrap entire key in quotes
# GOOGLE_SHEETS_SERVICE_ACCOUNT_PRIVATE_KEY="-----BEGIN PRIVATE KEY-----\\nMIIEvQIBADANBg...full_key_here...\\n-----END PRIVATE KEY-----\\n"

# Optional: Sheet name (defaults to "LLM Usage Log")
# GOOGLE_SHEETS_LOG_SHEET_NAME=LLM Usage Log

# ----------------------------------------------------------------
# AWS LAMBDA (Auto-set by AWS - do not configure manually)
# ----------------------------------------------------------------
# AWS_LAMBDA_FUNCTION_MEMORY_SIZE - Auto-set by Lambda runtime

# ================================================================
# DEPLOYMENT INSTRUCTIONS
# ================================================================
#
# 1. Copy this file:
#    cp .env.example .env
#
# 2. Fill in your actual API keys and configuration
#
# 3. Deploy to Lambda:
#    make deploy-env
#
# 4. Verify deployment:
#    make logs
#
# ================================================================
