{
  "version": "1.0.1",
  "lastUpdated": "2025-10-12",
  "chat": {
    "description": "Chat/completion LLM providers",
    "providers": {
      "groq-free": {
        "name": "Groq Free Tier",
        "type": "groq-free",
        "apiBase": "https://api.groq.com/openai/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": true,
          "limits": {
            "requestsPerMinute": 30,
            "requestsPerDay": 14400,
            "tokensPerMinute": 6000,
            "tokensPerDay": null
          }
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "meta-llama/llama-guard-4-12b": {
            "id": "meta-llama/llama-guard-4-12b",
            "category": "guardrail",
            "contextWindow": 131072,
            "maxOutput": 1024,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 15000,
              "tokensPerDay": 500000,
              "requestsPerMinute": 30,
              "requestsPerDay": 14400
            },
            "deprecated": false,
            "available": false,
            "guardrailModel": true,
            "excludeFromChat": true,
            "description": "Meta Llama Guard 4 12B - Specialized content moderation model (NOT for chat)"
          },
          "llama-3.1-8b-instant": {
            "id": "llama-3.1-8b-instant",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 6000,
              "tokensPerDay": 500000,
              "requestsPerMinute": 30,
              "requestsPerDay": 14400
            },
            "deprecated": false,
            "available": true,
            "description": "Meta Llama 3.1 8B - Fast and efficient, 560 tps"
          },
          "llama-3.3-70b-versatile": {
            "id": "llama-3.3-70b-versatile",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 32768,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 12000,
              "tokensPerDay": 100000,
              "requestsPerMinute": 30,
              "requestsPerDay": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Meta Llama 3.3 70B - Powerful and versatile, 280 tps"
          },
          "meta-llama/llama-4-maverick-17b-128e-instruct": {
            "id": "meta-llama/llama-4-maverick-17b-128e-instruct",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 6000,
              "tokensPerDay": 500000,
              "requestsPerMinute": 30,
              "requestsPerDay": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Meta Llama 4 Maverick 17B - Multimodal vision model with 128K context, 600 tps"
          },
          "meta-llama/llama-4-scout-17b-16e-instruct": {
            "id": "meta-llama/llama-4-scout-17b-16e-instruct",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 30000,
              "tokensPerDay": 500000,
              "requestsPerMinute": 30,
              "requestsPerDay": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Meta Llama 4 Scout 17B - Multimodal vision model with 128K context, 750 tps"
          },
          "moonshotai/kimi-k2-instruct": {
            "id": "moonshotai/kimi-k2-instruct",
            "category": "large",
            "contextWindow": 262144,
            "maxOutput": 16384,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 10000,
              "tokensPerDay": 300000,
              "requestsPerMinute": 60,
              "requestsPerDay": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Moonshot AI Kimi K2 - Ultra long context (262K tokens), 200 tps"
          },
          "moonshotai/kimi-k2-instruct-0905": {
            "id": "moonshotai/kimi-k2-instruct-0905",
            "category": "large",
            "contextWindow": 262144,
            "maxOutput": 16384,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 10000,
              "tokensPerDay": 300000,
              "requestsPerMinute": 60,
              "requestsPerDay": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Moonshot AI Kimi K2 (0905) - Ultra long context (262K tokens), 200 tps"
          },
          "openai/gpt-oss-20b": {
            "id": "openai/gpt-oss-20b",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 65536,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 8000,
              "tokensPerDay": 200000,
              "requestsPerMinute": 30,
              "requestsPerDay": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "OpenAI GPT OSS 20B - Open source model, 1000 tps"
          },
          "openai/gpt-oss-120b": {
            "id": "openai/gpt-oss-120b",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 65536,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 8000,
              "tokensPerDay": 200000,
              "requestsPerMinute": 30,
              "requestsPerDay": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "OpenAI GPT OSS 120B - Large open source model with reasoning, 500 tps"
          },
          "qwen/qwen3-32b": {
            "id": "qwen/qwen3-32b",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 40960,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 6000,
              "tokensPerDay": 500000,
              "requestsPerMinute": 60,
              "requestsPerDay": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Qwen 3 32B - Alibaba's latest model, 400 tps"
          },
          "allam-2-7b": {
            "id": "allam-2-7b",
            "category": "small",
            "contextWindow": 4096,
            "maxOutput": 4096,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 6000,
              "tokensPerDay": 500000,
              "requestsPerMinute": 30,
              "requestsPerDay": 7000
            },
            "deprecated": false,
            "available": true,
            "description": "SDAIA Allam 2 7B - Arabic-focused model"
          },
          "_deprecated_llama-3.2-11b-vision-preview": {
            "id": "llama-3.2-11b-vision-preview",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 7680,
              "tokensPerDay": 500000,
              "requestsPerMinute": 30,
              "requestsPerDay": 14400
            },
            "deprecated": true,
            "available": false,
            "deprecationDate": "2025-11-01",
            "deprecationReason": "Decommissioned by Groq on Nov 2025. Use llama-4-maverick-17b or llama-4-scout-17b instead.",
            "description": "Meta Llama 3.2 11B Vision - DEPRECATED: Use Llama 4 vision models instead"
          },
          "_deprecated_llama-3.2-90b-vision-preview": {
            "id": "llama-3.2-90b-vision-preview",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 7680,
              "tokensPerDay": 500000,
              "requestsPerMinute": 30,
              "requestsPerDay": 14400
            },
            "deprecated": true,
            "available": false,
            "deprecationReason": "Decommissioned by Groq on Nov 2025. Use llama-4-maverick-17b or llama-4-scout-17b instead.",
            "description": "Meta Llama 3.2 90B Vision - DEPRECATED: Use Llama 4 vision models instead"
          }
        }
      },
      "groq": {
        "name": "Groq Paid",
        "type": "groq",
        "apiBase": "https://api.groq.com/openai/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": false
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "meta-llama/llama-guard-4-12b": {
            "id": "meta-llama/llama-guard-4-12b",
            "category": "guardrail",
            "contextWindow": 131072,
            "maxOutput": 1024,
            "pricing": {
              "input": 0.20,
              "output": 0.20,
              "unit": "per_million_tokens"
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 15000,
              "tokensPerDay": 500000,
              "requestsPerMinute": 30,
              "requestsPerDay": 14400
            },
            "deprecated": false,
            "available": false,
            "guardrailModel": true,
            "excludeFromChat": true,
            "description": "Meta Llama Guard 4 12B - Specialized content moderation model (NOT for chat)"
          },
          "llama-3.1-8b-instant": {
            "id": "llama-3.1-8b-instant",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.05,
              "output": 0.08,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 30000,
              "requestsPerMinute": 7000
            },
            "deprecated": false,
            "available": true
          },
          "llama-3.3-70b-versatile": {
            "id": "llama-3.3-70b-versatile",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 32768,
            "pricing": {
              "input": 0.59,
              "output": 0.79,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 6000,
              "requestsPerMinute": 30
            },
            "deprecated": false,
            "available": true
          },
          "meta-llama/llama-4-maverick-17b-128e-instruct": {
            "id": "meta-llama/llama-4-maverick-17b-128e-instruct",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.20,
              "output": 0.60,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 300000,
              "requestsPerMinute": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Meta Llama 4 Maverick 17B - Multimodal vision model with 128K context, 600 tps"
          },
          "meta-llama/llama-4-scout-17b-16e-instruct": {
            "id": "meta-llama/llama-4-scout-17b-16e-instruct",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.11,
              "output": 0.34,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 300000,
              "requestsPerMinute": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Meta Llama 4 Scout 17B - Multimodal vision model with 128K context, 750 tps"
          },
          "moonshotai/kimi-k2-instruct": {
            "id": "moonshotai/kimi-k2-instruct",
            "category": "large",
            "contextWindow": 262144,
            "maxOutput": 16384,
            "pricing": {
              "input": 1.00,
              "output": 3.00,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 250000,
              "requestsPerMinute": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Moonshot AI Kimi K2 - Ultra long context (262K tokens), 200 tps"
          },
          "moonshotai/kimi-k2-instruct-0905": {
            "id": "moonshotai/kimi-k2-instruct-0905",
            "category": "large",
            "contextWindow": 262144,
            "maxOutput": 16384,
            "pricing": {
              "input": 1.00,
              "output": 3.00,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 250000,
              "requestsPerMinute": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Moonshot AI Kimi K2 (0905) - Ultra long context (262K tokens), 200 tps"
          },
          "openai/gpt-oss-20b": {
            "id": "openai/gpt-oss-20b",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 65536,
            "pricing": {
              "input": 0.075,
              "output": 0.30,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 250000,
              "requestsPerMinute": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "OpenAI GPT OSS 20B - Open source model, 1000 tps"
          },
          "openai/gpt-oss-120b": {
            "id": "openai/gpt-oss-120b",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 65536,
            "pricing": {
              "input": 0.15,
              "output": 0.60,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 250000,
              "requestsPerMinute": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "OpenAI GPT OSS 120B - Large open source model with reasoning, 500 tps"
          },
          "qwen/qwen3-32b": {
            "id": "qwen/qwen3-32b",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 40960,
            "pricing": {
              "input": 0.29,
              "output": 0.59,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 300000,
              "requestsPerMinute": 1000
            },
            "deprecated": false,
            "available": true,
            "description": "Qwen 3 32B - Alibaba's latest model, 400 tps"
          },
          "allam-2-7b": {
            "id": "allam-2-7b",
            "category": "small",
            "contextWindow": 4096,
            "maxOutput": 4096,
            "pricing": {
              "input": 0.05,
              "output": 0.08,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 30000,
              "requestsPerMinute": 7000
            },
            "deprecated": false,
            "available": true,
            "description": "SDAIA Allam 2 7B - Arabic-focused model"
          },
          "llama-3.2-11b-vision-preview": {
            "id": "llama-3.2-11b-vision-preview",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.055,
              "output": 0.055,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 60000,
              "requestsPerMinute": 1000
            },
            "deprecated": true,
            "available": false,
            "deprecationReason": "Decommissioned by Groq on Nov 2025. Use llama-4-maverick-17b or llama-4-scout-17b instead.",
            "description": "Meta Llama 3.2 11B Vision - DEPRECATED: Use Llama 4 vision models instead"
          },
          "_deprecated_llama-3.2-90b-vision-preview": {
            "id": "llama-3.2-90b-vision-preview",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.90,
              "output": 0.90,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 60000,
              "requestsPerMinute": 1000
            },
            "deprecated": true,
            "available": false,
            "deprecationReason": "Decommissioned by Groq on Nov 2025. Use llama-4-maverick-17b or llama-4-scout-17b instead.",
            "description": "Meta Llama 3.2 90B Vision - DEPRECATED: Use Llama 4 vision models instead"
          },
          "mixtral-8x7b-32768": {
            "id": "mixtral-8x7b-32768",
            "category": "large",
            "contextWindow": 32768,
            "maxOutput": 32768,
            "pricing": {
              "input": 0.24,
              "output": 0.24,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 5000,
              "requestsPerMinute": 30
            },
            "deprecated": true,
            "available": false,
            "deprecationReason": "Decommissioned by Groq on Oct 2025"
          }
        }
      },
      "openai": {
        "name": "OpenAI",
        "type": "openai",
        "apiBase": "https://api.openai.com/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "supportsVision": true,
        "freeTier": {
          "available": false
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "gpt-4o-mini": {
            "id": "gpt-4o-mini",
            "category": "small",
            "contextWindow": 128000,
            "maxOutput": 16384,
            "pricing": {
              "input": 0.15,
              "output": 0.6,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 2000000,
              "requestsPerMinute": 10000
            },
            "deprecated": false,
            "available": true
          },
          "gpt-4o": {
            "id": "gpt-4o",
            "category": "large",
            "contextWindow": 128000,
            "maxOutput": 16384,
            "pricing": {
              "input": 2.5,
              "output": 10,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 800000,
              "requestsPerMinute": 10000
            },
            "deprecated": false,
            "available": true
          },
          "o1-preview": {
            "id": "o1-preview",
            "category": "reasoning",
            "contextWindow": 128000,
            "maxOutput": 32768,
            "pricing": {
              "input": 15,
              "output": 60,
              "unit": "per_million_tokens"
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": false,
            "rateLimits": {
              "tokensPerMinute": 40000,
              "requestsPerMinute": 500
            },
            "deprecated": false,
            "available": true
          },
          "o1-mini": {
            "id": "o1-mini",
            "category": "reasoning",
            "contextWindow": 128000,
            "maxOutput": 65536,
            "pricing": {
              "input": 3,
              "output": 12,
              "unit": "per_million_tokens"
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": false,
            "rateLimits": {
              "tokensPerMinute": 200000,
              "requestsPerMinute": 500
            },
            "capabilities": [
              "chat",
              "reasoning"
            ],
            "deprecated": false,
            "available": true
          }
        }
      },
      "gemini-free": {
        "name": "Google Gemini Free Tier",
        "type": "gemini-free",
        "apiBase": "https://generativelanguage.googleapis.com/v1beta",
        "supportsStreaming": true,
        "supportsTools": true,
        "supportsVision": true,
        "freeTier": {
          "available": true,
          "limits": {
            "requestsPerMinute": 15,
            "requestsPerDay": 1500,
            "tokensPerMinute": 1000000,
            "tokensPerDay": 50000000
          }
        },
        "rateLimitHeaders": {
          "format": "custom",
          "note": "May not expose all limits in headers"
        },
        "models": {
          "gemini-2.5-flash": {
            "id": "gemini-2.5-flash",
            "category": "small",
            "contextWindow": 1000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 1000000,
              "requestsPerMinute": 15
            },
            "deprecated": false,
            "available": true
          },
          "gemini-2.5-pro": {
            "id": "gemini-2.5-pro",
            "category": "large",
            "contextWindow": 2000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": false,
            "rateLimits": {
              "tokensPerMinute": 1000000,
              "requestsPerMinute": 15
            },
            "deprecated": false,
            "available": true
          },
          "gemini-2.0-flash-exp": {
            "id": "gemini-2.0-flash-exp",
            "category": "large",
            "contextWindow": 1000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 1000000,
              "requestsPerMinute": 15
            },
            "deprecated": false,
            "available": true
          }
        }
      },
      "gemini": {
        "name": "Google Gemini Paid",
        "type": "gemini",
        "apiBase": "https://generativelanguage.googleapis.com/v1beta",
        "supportsStreaming": true,
        "supportsTools": true,
        "supportsVision": true,
        "freeTier": {
          "available": false
        },
        "rateLimitHeaders": {
          "format": "custom",
          "note": "May not expose all limits in headers"
        },
        "models": {
          "gemini-2.5-flash": {
            "id": "gemini-2.5-flash",
            "category": "small",
            "contextWindow": 1000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.075,
              "output": 0.3,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 1500
            },
            "deprecated": false,
            "available": true
          },
          "gemini-2.5-pro": {
            "id": "gemini-2.5-pro",
            "category": "large",
            "contextWindow": 2000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 1.25,
              "output": 5.0,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 360
            },
            "deprecated": false,
            "available": true
          },
          "gemini-2.0-flash-exp": {
            "id": "gemini-2.0-flash-exp",
            "category": "large",
            "contextWindow": 1000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 10
            },
            "deprecated": false,
            "available": true
          },
          "gemini-exp-1206": {
            "id": "gemini-exp-1206",
            "category": "large",
            "contextWindow": 2000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 10
            },
            "deprecated": false,
            "available": true
          }
        }
      },
      "cohere": {
        "name": "Cohere",
        "type": "cohere",
        "apiBase": "https://api.cohere.ai/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": false,
          "limits": {
            "note": "Trial credits available for new users, then pay-as-you-go"
          }
        },
        "rateLimitHeaders": {
          "format": "custom",
          "note": "Rate limits in headers may vary"
        },
        "models": {
          "command-r7b-12-2024": {
            "id": "command-r7b-12-2024",
            "category": "small",
            "contextWindow": 128000,
            "maxOutput": 4096,
            "pricing": {
              "input": 0.075,
              "output": 0.30,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 10000,
              "requestsPerMinute": 100
            },
            "deprecated": false,
            "available": true,
            "description": "Cohere Command R7B - Lightweight and cost-effective"
          },
          "command-r-08-2024": {
            "id": "command-r-08-2024",
            "category": "large",
            "contextWindow": 128000,
            "maxOutput": 4096,
            "pricing": {
              "input": 0.15,
              "output": 0.60,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 10000,
              "requestsPerMinute": 100
            },
            "deprecated": false,
            "available": true,
            "description": "Cohere Command R - Balanced performance and cost"
          },
          "command-r-plus-08-2024": {
            "id": "command-r-plus-08-2024",
            "category": "large",
            "contextWindow": 128000,
            "maxOutput": 4096,
            "pricing": {
              "input": 2.50,
              "output": 10.00,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 10000,
              "requestsPerMinute": 100
            },
            "deprecated": false,
            "available": true,
            "description": "Cohere Command R Plus - Premium model for complex tasks"
          },
          "command-r": {
            "id": "command-r",
            "category": "large",
            "contextWindow": 128000,
            "maxOutput": 4096,
            "pricing": {
              "input": 0.15,
              "output": 0.60,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 10000,
              "requestsPerMinute": 100
            },
            "deprecated": false,
            "available": true,
            "description": "Cohere Command R - Latest stable version"
          },
          "command-r-plus": {
            "id": "command-r-plus",
            "category": "large",
            "contextWindow": 128000,
            "maxOutput": 4096,
            "pricing": {
              "input": 2.50,
              "output": 10.00,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 10000,
              "requestsPerMinute": 100
            },
            "deprecated": false,
            "available": true,
            "description": "Cohere Command R Plus - Latest stable premium version"
          }
        }
      },
      "together": {
        "name": "Together AI",
        "type": "together",
        "apiBase": "https://api.together.xyz/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": false,
          "limits": {
            "note": "No free tier - $25 trial credits for new users, then pay-as-you-go"
          }
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "virtueguard-text-lite": {
            "id": "virtueguard-text-lite",
            "category": "guardrail",
            "contextWindow": 8192,
            "maxOutput": 512,
            "pricing": {
              "input": 0.10,
              "output": 0.10,
              "unit": "per_million_tokens"
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true,
            "guardrailModel": true,
            "description": "VirtueGuard Text Lite - Specialized content moderation model"
          },
          "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
            "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 32768,
            "pricing": {
              "input": 0.88,
              "output": 0.88,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free": {
            "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 32768,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": false,
              "note": "Uses trial credits - not truly free"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 10
            },
            "deprecated": false,
            "available": true,
            "note": "Reduced rate limits, uses trial credits"
          },
          "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
            "id": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 4096,
            "pricing": {
              "input": 0.88,
              "output": 0.88,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
            "id": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 4096,
            "pricing": {
              "input": 0.18,
              "output": 0.18,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
            "id": "meta-llama/Llama-3.2-3B-Instruct-Turbo",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.06,
              "output": 0.06,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "Qwen/Qwen2.5-72B-Instruct-Turbo": {
            "id": "Qwen/Qwen2.5-72B-Instruct-Turbo",
            "category": "large",
            "contextWindow": 32768,
            "maxOutput": 8192,
            "pricing": {
              "input": 1.20,
              "output": 1.20,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "Qwen/Qwen2.5-7B-Instruct-Turbo": {
            "id": "Qwen/Qwen2.5-7B-Instruct-Turbo",
            "category": "small",
            "contextWindow": 32768,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.30,
              "output": 0.30,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "deepseek-ai/DeepSeek-R1": {
            "id": "deepseek-ai/DeepSeek-R1",
            "category": "reasoning",
            "contextWindow": 163839,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.55,
              "output": 2.19,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "deepseek-ai/DeepSeek-V3": {
            "id": "deepseek-ai/DeepSeek-V3",
            "category": "large",
            "contextWindow": 163839,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.27,
              "output": 1.10,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "mistralai/Mixtral-8x7B-Instruct-v0.1": {
            "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "category": "large",
            "contextWindow": 32768,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.60,
              "output": 0.60,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          }
        }
      },
      "atlascloud": {
        "name": "Atlas Cloud",
        "type": "atlascloud",
        "apiBase": "https://api.atlascloud.ai/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": false
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "deepseek-ai/DeepSeek-R1": {
            "id": "deepseek-ai/DeepSeek-R1",
            "category": "reasoning",
            "contextWindow": 65536,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.55,
              "output": 2.19,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 60
            },
            "deprecated": false,
            "available": true
          },
          "deepseek-ai/DeepSeek-V3": {
            "id": "deepseek-ai/DeepSeek-V3",
            "category": "large",
            "contextWindow": 65536,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.27,
              "output": 1.10,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 60
            },
            "deprecated": false,
            "available": true
          },
          "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
            "id": "meta-llama/Llama-3.3-70B-Instruct-Turbo",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 32768,
            "pricing": {
              "input": 0.88,
              "output": 0.88,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 60
            },
            "deprecated": false,
            "available": true
          }
        }
      },
      "anthropic": {
        "name": "Anthropic",
        "type": "anthropic",
        "apiBase": "https://api.anthropic.com/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": false
        },
        "models": {
          "claude-sonnet-4-5-20250929": {
            "id": "claude-sonnet-4-5-20250929",
            "category": "flagship",
            "contextWindow": 200000,
            "maxOutput": 8192,
            "pricing": {
              "input": 3.00,
              "output": 15.00,
              "unit": "per_million_tokens",
              "free": false
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "deprecated": false,
            "available": true,
            "description": "Claude Sonnet 4.5 - Most intelligent model with best-in-class reasoning"
          },
          "claude-3-7-sonnet-20250219": {
            "id": "claude-3-7-sonnet-20250219",
            "category": "large",
            "contextWindow": 200000,
            "maxOutput": 8192,
            "pricing": {
              "input": 3.00,
              "output": 15.00,
              "unit": "per_million_tokens",
              "free": false
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "deprecated": false,
            "available": true,
            "description": "Claude 3.7 Sonnet - Balanced performance and speed"
          },
          "claude-3-5-haiku-20241022": {
            "id": "claude-3-5-haiku-20241022",
            "category": "small",
            "contextWindow": 200000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.80,
              "output": 4.00,
              "unit": "per_million_tokens",
              "free": false
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "deprecated": false,
            "available": true,
            "description": "Claude 3.5 Haiku - Fast and cost-effective"
          }
        }
      }
    }
  },
  "whisper": {
    "description": "Speech-to-text transcription models",
    "providers": {
      "openai": {
        "name": "OpenAI Whisper",
        "available": true,
        "apiBase": "https://api.openai.com/v1",
        "endpoint": "/audio/transcriptions",
        "models": {
          "whisper-1": {
            "id": "whisper-1",
            "pricing": {
              "perMinute": 0.006,
              "unit": "per_minute"
            },
            "maxFileSize": "25MB",
            "supportedFormats": [
              "mp3",
              "mp4",
              "mpeg",
              "mpga",
              "m4a",
              "wav",
              "webm"
            ],
            "supportsTimestamps": true,
            "supportsTranslation": true
          }
        }
      },
      "groq": {
        "name": "Groq Whisper",
        "available": true,
        "apiBase": "https://api.groq.com/openai/v1",
        "endpoint": "/audio/transcriptions",
        "models": {
          "whisper-large-v3": {
            "id": "whisper-large-v3",
            "pricing": {
              "perMinute": 0,
              "unit": "per_minute",
              "free": true
            },
            "maxFileSize": "25MB",
            "supportedFormats": [
              "mp3",
              "mp4",
              "mpeg",
              "mpga",
              "m4a",
              "wav",
              "webm"
            ],
            "supportsTimestamps": true,
            "supportsTranslation": false,
            "rateLimits": {
              "requestsPerMinute": 20,
              "requestsPerDay": 1000
            }
          }
        }
      },
      "speaches": {
        "name": "Speaches Local",
        "type": "speaches",
        "apiBase": "http://localhost:8000",
        "supportsStreaming": false,
        "supportsTools": false,
        "freeTier": {
          "available": true,
          "limits": {}
        },
        "models": {
          "whisper-1": {
            "id": "whisper-1",
            "category": "transcription",
            "contextWindow": 0,
            "maxOutput": 0,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_minute",
              "free": true
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": false,
            "available": true,
            "deprecated": false,
            "supportsTimestamps": true,
            "supportsTranslation": false
          },
          "tts-1": {
            "id": "tts-1",
            "category": "text-to-speech",
            "contextWindow": 0,
            "maxOutput": 0,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_character",
              "free": true
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": false,
            "available": true,
            "deprecated": false
          }
        }
      },
      "replicate": {
        "name": "Replicate",
        "type": "replicate",
        "apiBase": "https://api.replicate.com/v1",
        "supportsStreaming": true,
        "supportsTools": false,
        "freeTier": {
          "available": false,
          "limits": {}
        },
        "rateLimits": {
          "createPrediction": 600,
          "otherEndpoints": 3000,
          "unit": "per_minute"
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "ratelimit-"
        },
        "models": {
          "xai/grok-4": {
            "id": "xai/grok-4",
            "category": "reasoning",
            "contextWindow": 128000,
            "qualityTier": "ultra",
            "pricing": {"input": 10.0, "output": 30.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "Grok 4 - xAI's most advanced reasoning model"
          },
          "openai/o1": {
            "id": "openai/o1",
            "category": "reasoning",
            "contextWindow": 128000,
            "qualityTier": "ultra",
            "pricing": {"input": 15.0, "output": 60.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "OpenAI o1 - first o-series reasoning model"
          },
          "meta/meta-llama-3.1-405b-instruct": {
            "id": "meta/meta-llama-3.1-405b-instruct",
            "category": "reasoning",
            "contextWindow": 128000,
            "qualityTier": "ultra",
            "pricing": {"input": 9.5, "output": 9.5, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "Meta Llama 3.1 405B - flagship 405B parameter model"
          },
          "openai/gpt-5": {
            "id": "openai/gpt-5",
            "category": "reasoning",
            "contextWindow": 128000,
            "qualityTier": "ultra",
            "pricing": {"input": 5.0, "output": 15.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT-5 - excelling at coding, writing, and reasoning"
          },
          "anthropic/claude-4.5-sonnet": {
            "id": "anthropic/claude-4.5-sonnet",
            "category": "reasoning",
            "contextWindow": 200000,
            "qualityTier": "ultra",
            "pricing": {"input": 3.0, "output": 15.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "Claude 4.5 Sonnet - best coding model with development lifecycle improvements"
          },
          "anthropic/claude-4-sonnet": {
            "id": "anthropic/claude-4-sonnet",
            "category": "reasoning",
            "contextWindow": 200000,
            "qualityTier": "ultra",
            "pricing": {"input": 3.0, "output": 15.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "Claude 4 Sonnet - superior coding and reasoning"
          },
          "anthropic/claude-3.7-sonnet": {
            "id": "anthropic/claude-3.7-sonnet",
            "category": "reasoning",
            "contextWindow": 200000,
            "qualityTier": "ultra",
            "pricing": {"input": 3.0, "output": 15.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "Claude 3.7 Sonnet - first hybrid reasoning model on market"
          },
          "anthropic/claude-3.5-sonnet": {
            "id": "anthropic/claude-3.5-sonnet",
            "category": "reasoning",
            "contextWindow": 200000,
            "qualityTier": "ultra",
            "pricing": {"input": 3.0, "output": 15.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "Claude 3.5 Sonnet - most intelligent Claude with image understanding"
          },
          "openai/o4-mini": {
            "id": "openai/o4-mini",
            "category": "reasoning",
            "contextWindow": 128000,
            "qualityTier": "premium",
            "pricing": {"input": 3.0, "output": 12.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "o4 Mini - fast, lightweight reasoning model"
          },
          "openai/o1-mini": {
            "id": "openai/o1-mini",
            "category": "reasoning",
            "contextWindow": 128000,
            "qualityTier": "premium",
            "pricing": {"input": 3.0, "output": 12.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "o1 Mini - small model alternative to o1"
          },
          "deepseek-ai/deepseek-r1": {
            "id": "deepseek-ai/deepseek-r1",
            "category": "reasoning",
            "contextWindow": 64000,
            "qualityTier": "premium",
            "pricing": {"input": 3.75, "output": 0.01, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "DeepSeek R1 - reasoning model on par with OpenAI o1"
          },
          "google/gemini-2.5-flash": {
            "id": "google/gemini-2.5-flash",
            "category": "reasoning",
            "contextWindow": 1000000,
            "qualityTier": "premium",
            "pricing": {"input": 2.5, "output": 2.5, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "Gemini 2.5 Flash - hybrid thinking AI optimized for speed and cost-efficiency"
          },
          "openai/gpt-4.1": {
            "id": "openai/gpt-4.1",
            "category": "reasoning",
            "contextWindow": 128000,
            "qualityTier": "premium",
            "pricing": {"input": 2.5, "output": 10.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT-4.1 - flagship model for complex tasks"
          },
          "openai/gpt-4o": {
            "id": "openai/gpt-4o",
            "category": "multimodal",
            "contextWindow": 128000,
            "qualityTier": "premium",
            "pricing": {"input": 2.5, "output": 10.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT-4o - high-intelligence chat model"
          },
          "moonshotai/kimi-k2-instruct": {
            "id": "moonshotai/kimi-k2-instruct",
            "category": "reasoning",
            "contextWindow": 200000,
            "qualityTier": "premium",
            "pricing": {"input": 2.0, "output": 8.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "Kimi K2 - exceptional reasoning, coding and agentic capabilities"
          },
          "qwen/qwen3-235b-a22b-instruct-2507": {
            "id": "qwen/qwen3-235b-a22b-instruct-2507",
            "category": "general",
            "contextWindow": 32000,
            "qualityTier": "premium",
            "pricing": {"input": 1.1, "output": 4.4, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "Qwen3 235B A22B - updated model for instruction following"
          },
          "anthropic/claude-3.5-haiku": {
            "id": "anthropic/claude-3.5-haiku",
            "category": "fast",
            "contextWindow": 200000,
            "qualityTier": "standard",
            "pricing": {"input": 0.8, "output": 4.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "Claude 3.5 Haiku - fastest, most cost-effective Claude model"
          },
          "anthropic/claude-4.5-haiku": {
            "id": "anthropic/claude-4.5-haiku",
            "category": "fast",
            "contextWindow": 200000,
            "qualityTier": "standard",
            "pricing": {"input": 1.0, "output": 5.0, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "Claude 4.5 Haiku - coding performance at one-third cost, twice the speed"
          },
          "meta/meta-llama-3-70b-instruct": {
            "id": "meta/meta-llama-3-70b-instruct",
            "category": "large",
            "contextWindow": 8000,
            "qualityTier": "standard",
            "pricing": {"input": 0.65, "output": 2.75, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "Llama 3 70B Instruct - fine-tuned for chat completions"
          },
          "deepseek-ai/deepseek-v3.1": {
            "id": "deepseek-ai/deepseek-v3.1",
            "category": "reasoning",
            "contextWindow": 64000,
            "qualityTier": "premium",
            "pricing": {"input": 0.55, "output": 2.19, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "DeepSeek V3.1 - latest hybrid thinking model"
          },
          "openai/gpt-5-mini": {
            "id": "openai/gpt-5-mini",
            "category": "fast",
            "contextWindow": 128000,
            "qualityTier": "standard",
            "pricing": {"input": 0.55, "output": 2.2, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT-5 Mini - faster version of GPT-5"
          },
          "openai/gpt-4.1-mini": {
            "id": "openai/gpt-4.1-mini",
            "category": "fast",
            "contextWindow": 128000,
            "qualityTier": "standard",
            "pricing": {"input": 0.4, "output": 1.6, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT-4.1 Mini - fast, affordable version of GPT-4.1"
          },
          "openai/gpt-oss-120b": {
            "id": "openai/gpt-oss-120b",
            "category": "general",
            "contextWindow": 32000,
            "qualityTier": "standard",
            "pricing": {"input": 0.4, "output": 1.2, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT OSS 120B - 120B open-weight language model"
          },
          "deepseek-ai/deepseek-v3": {
            "id": "deepseek-ai/deepseek-v3",
            "category": "reasoning",
            "contextWindow": 64000,
            "qualityTier": "standard",
            "pricing": {"input": 0.27, "output": 1.1, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "DeepSeek V3 - leading non-reasoning model, milestone for open source"
          },
          "openai/gpt-5-nano": {
            "id": "openai/gpt-5-nano",
            "category": "fast",
            "contextWindow": 128000,
            "qualityTier": "standard",
            "pricing": {"input": 0.15, "output": 0.6, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT-5 Nano - fastest, most cost-effective GPT-5"
          },
          "openai/gpt-4o-mini": {
            "id": "openai/gpt-4o-mini",
            "category": "fast",
            "contextWindow": 128000,
            "qualityTier": "standard",
            "pricing": {"input": 0.15, "output": 0.6, "unit": "per_million_tokens", "free": false},
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT-4o Mini - low latency, low cost GPT-4o"
          },
          "openai/gpt-oss-20b": {
            "id": "openai/gpt-oss-20b",
            "category": "general",
            "contextWindow": 16000,
            "qualityTier": "standard",
            "pricing": {"input": 0.1, "output": 0.3, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT OSS 20B - 20B open-weight language model"
          },
          "openai/gpt-4.1-nano": {
            "id": "openai/gpt-4.1-nano",
            "category": "fast",
            "contextWindow": 128000,
            "qualityTier": "budget",
            "pricing": {"input": 0.1, "output": 0.4, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "GPT-4.1 Nano - fastest, most cost-effective GPT-4.1"
          },
          "meta/meta-llama-3-8b-instruct": {
            "id": "meta/meta-llama-3-8b-instruct",
            "category": "small",
            "contextWindow": 8000,
            "qualityTier": "budget",
            "pricing": {"input": 0.05, "output": 0.25, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "Llama 3 8B Instruct - fast and cost-effective"
          },
          "ibm-granite/granite-3.3-8b-instruct": {
            "id": "ibm-granite/granite-3.3-8b-instruct",
            "category": "general",
            "contextWindow": 128000,
            "qualityTier": "budget",
            "pricing": {"input": 0.05, "output": 0.25, "unit": "per_million_tokens", "free": false},
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": true,
            "available": true,
            "description": "Granite 3.3 8B - improved reasoning and instruction-following"
          }
        },
        "textToSpeech": {
          "supportsStreaming": false,
          "models": {
            "resemble-ai/chatterbox": {
              "id": "resemble-ai/chatterbox",
              "qualityTier": "premium",
              "pricing": {"default": 0.025, "unit": "per_thousand_characters", "free": false},
              "features": ["emotion-control", "voice-cloning", "watermarking"],
              "languages": ["en"],
              "available": true,
              "description": "Chatterbox - expressive speech with emotion control and instant voice cloning"
            },
            "resemble-ai/chatterbox-pro": {
              "id": "resemble-ai/chatterbox-pro",
              "qualityTier": "ultra",
              "pricing": {"default": 0.04, "unit": "per_thousand_characters", "free": false},
              "features": ["emotion-control", "voice-cloning", "watermarking"],
              "languages": ["en"],
              "available": true,
              "description": "Chatterbox Pro - professional-grade expressive speech generation"
            },
            "resemble-ai/chatterbox-multilingual": {
              "id": "resemble-ai/chatterbox-multilingual",
              "qualityTier": "ultra",
              "pricing": {"default": 0.035, "unit": "per_thousand_characters", "free": false},
              "features": ["emotion-control", "voice-cloning", "multilingual", "cross-language-transfer"],
              "languages": ["en", "es", "fr", "de", "it", "pt", "zh", "ja", "ko", "ar", "hi", "ru", "tr", "pl", "nl", "sv", "da", "no", "fi", "cs", "el", "he", "th"],
              "available": true,
              "description": "Chatterbox Multilingual - expressive speech in 23 languages with instant voice cloning"
            },
            "minimax/speech-02-turbo": {
              "id": "minimax/speech-02-turbo",
              "qualityTier": "standard",
              "pricing": {"default": 0.0001, "unit": "per_second", "free": false},
              "features": ["emotion-expression", "multilingual", "low-latency"],
              "languages": ["en", "zh", "ja", "ko", "es", "fr", "de"],
              "available": true,
              "description": "Speech-02 Turbo - real-time TTS with low latency for voice agents"
            },
            "minimax/speech-02-hd": {
              "id": "minimax/speech-02-hd",
              "qualityTier": "premium",
              "pricing": {"default": 0.0002, "unit": "per_second", "free": false},
              "features": ["emotion-expression", "multilingual", "high-fidelity"],
              "languages": ["en", "zh", "ja", "ko", "es", "fr", "de"],
              "available": true,
              "description": "Speech-02 HD - high-fidelity TTS optimized for voiceovers and audiobooks"
            },
            "jaaari/kokoro-82m": {
              "id": "jaaari/kokoro-82m",
              "qualityTier": "budget",
              "pricing": {"default": 0.00005, "unit": "per_second", "free": false},
              "features": ["fast", "lightweight"],
              "languages": ["en"],
              "available": true,
              "description": "Kokoro 82M - lightweight 82M parameter TTS based on StyleTTS2"
            },
            "x-lance/f5-tts": {
              "id": "x-lance/f5-tts",
              "qualityTier": "standard",
              "pricing": {"default": 0.0001, "unit": "per_second", "free": false},
              "features": ["voice-cloning"],
              "languages": ["en"],
              "available": true,
              "description": "F5-TTS - state-of-the-art open source voice cloning"
            }
          }
        },
        "speechToText": {
          "models": {
            "openai/gpt-4o-transcribe": {
              "id": "openai/gpt-4o-transcribe",
              "qualityTier": "premium",
              "pricing": {"default": 0.006, "unit": "per_minute", "free": false},
              "features": ["fast", "accurate", "multilingual"],
              "languages": ["auto-detect"],
              "available": true,
              "description": "GPT-4o Transcribe - speech-to-text using GPT-4o"
            },
            "openai/gpt-4o-mini-transcribe": {
              "id": "openai/gpt-4o-mini-transcribe",
              "qualityTier": "standard",
              "pricing": {"default": 0.002, "unit": "per_minute", "free": false},
              "features": ["fast", "accurate", "multilingual"],
              "languages": ["auto-detect"],
              "available": true,
              "description": "GPT-4o Mini Transcribe - cost-effective speech-to-text using GPT-4o mini"
            },
            "vaibhavs10/incredibly-fast-whisper": {
              "id": "vaibhavs10/incredibly-fast-whisper",
              "qualityTier": "standard",
              "pricing": {"default": 0.001, "unit": "per_minute", "free": false},
              "features": ["very-fast", "accurate", "multilingual"],
              "languages": ["auto-detect"],
              "available": true,
              "description": "Incredibly Fast Whisper - 10x faster than original Whisper with large-v3"
            },
            "victor-upmeet/whisperx": {
              "id": "victor-upmeet/whisperx",
              "qualityTier": "premium",
              "pricing": {"default": 0.003, "unit": "per_minute", "free": false},
              "features": ["diarization", "word-timestamps", "accurate", "multilingual"],
              "languages": ["auto-detect"],
              "available": true,
              "description": "WhisperX - accelerated transcription with speaker diarization and word-level timestamps"
            },
            "thomasmol/whisper-diarization": {
              "id": "thomasmol/whisper-diarization",
              "qualityTier": "standard",
              "pricing": {"default": 0.002, "unit": "per_minute", "free": false},
              "features": ["diarization", "word-timestamps", "sentence-timestamps", "fast"],
              "languages": ["auto-detect"],
              "available": true,
              "description": "Whisper Diarization - blazing fast with Whisper Large V3 Turbo and speaker identification"
            },
            "openai/whisper": {
              "id": "openai/whisper",
              "qualityTier": "standard",
              "pricing": {"default": 0.0015, "unit": "per_minute", "free": false},
              "features": ["accurate", "multilingual"],
              "languages": ["auto-detect"],
              "available": true,
              "description": "OpenAI Whisper - general-purpose speech-to-text"
            }
          }
        }
      }
    }
  },
  "imageGeneration": {
    "description": "Text-to-image generation models",
    "providers": {
      "openai": {
        "name": "OpenAI DALL-E",
        "available": true,
        "apiBase": "https://api.openai.com/v1",
        "endpoint": "/images/generations",
        "models": {
          "dall-e-3": {
            "id": "dall-e-3",
            "pricing": {
              "standard": {
                "1024x1024": 0.04,
                "1024x1792": 0.08,
                "1792x1024": 0.08
              },
              "hd": {
                "1024x1024": 0.08,
                "1024x1792": 0.12,
                "1792x1024": 0.12
              },
              "unit": "per_image"
            },
            "supportedSizes": [
              "1024x1024",
              "1024x1792",
              "1792x1024"
            ],
            "quality": [
              "standard",
              "hd"
            ],
            "style": [
              "vivid",
              "natural"
            ]
          },
          "dall-e-2": {
            "id": "dall-e-2",
            "pricing": {
              "1024x1024": 0.02,
              "512x512": 0.018,
              "256x256": 0.016,
              "unit": "per_image"
            },
            "supportedSizes": [
              "1024x1024",
              "512x512",
              "256x256"
            ]
          }
        }
      },
      "together": {
        "name": "Together AI Image Models",
        "available": true,
        "apiBase": "https://api.together.xyz/v1",
        "endpoint": "/images/generations",
        "models": {
          "stabilityai/stable-diffusion-xl-base-1.0": {
            "id": "stabilityai/stable-diffusion-xl-base-1.0",
            "pricing": {
              "perImage": 0.002,
              "unit": "per_image"
            },
            "supportedSizes": [
              "1024x1024",
              "512x512",
              "768x768"
            ],
            "steps": {
              "min": 1,
              "max": 100,
              "default": 20
            }
          },
          "runwayml/stable-diffusion-v1-5": {
            "id": "runwayml/stable-diffusion-v1-5",
            "pricing": {
              "perImage": 0.001,
              "unit": "per_image"
            },
            "supportedSizes": [
              "512x512",
              "768x768"
            ],
            "steps": {
              "min": 1,
              "max": 100,
              "default": 20
            }
          }
        }
      }
    }
  },
  "openaiCompatibleEndpoints": [
    {
      "name": "Anyscale Endpoints",
      "endpoint": "https://api.endpoints.anyscale.com/v1",
      "description": "Ray-powered serverless LLM inference",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "Anyscale Endpoints",
      "endpoint": "https://api.endpoints.anyscale.com/v1",
      "description": "Ray-powered serverless LLM inference",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "Perplexity AI",
      "endpoint": "https://api.perplexity.ai",
      "description": "Search-augmented language models",
      "supported": [
        "chat",
        "streaming"
      ]
    },
    {
      "name": "DeepInfra",
      "endpoint": "https://api.deepinfra.com/v1/openai",
      "description": "Fast inference for popular models",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "Fireworks AI",
      "endpoint": "https://api.fireworks.ai/inference/v1",
      "description": "Production-ready LLM platform",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "Ollama (Local)",
      "endpoint": "http://localhost:11434/v1",
      "description": "Run models locally on your machine",
      "supported": [
        "chat",
        "streaming"
      ]
    },
    {
      "name": "LM Studio (Local)",
      "endpoint": "http://localhost:1234/v1",
      "description": "Run models locally via LM Studio",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "LocalAI (Local)",
      "endpoint": "http://localhost:8080/v1",
      "description": "Local OpenAI-compatible API",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    }
  ],
  "modelCategories": {
    "small": {
      "description": "Fast, cost-effective models for simple tasks",
      "useCases": [
        "summarization",
        "quick responses",
        "simple queries"
      ],
      "maxCost": 0.5
    },
    "large": {
      "description": "General-purpose models for most tasks",
      "useCases": [
        "chat",
        "complex queries",
        "tool usage"
      ],
      "maxCost": 5
    },
    "reasoning": {
      "description": "Optimized for multi-step reasoning and analysis",
      "useCases": [
        "planning",
        "analysis",
        "complex problem solving"
      ],
      "maxCost": 20
    }
  },
  "image": {
    "description": "Image generation providers and models",
    "providers": {
      "openai": {
        "name": "OpenAI",
        "type": "openai",
        "apiBase": "https://api.openai.com/v1",
        "supportsStyles": true,
        "models": {
          "dall-e-3": {
            "id": "dall-e-3",
            "type": "image",
            "qualityTier": "high",
            "contextWindow": 4000,
            "supportedSizes": ["1024x1024", "1792x1024", "1024x1792"],
            "supportedQualities": ["standard", "hd"],
            "pricing": {
              "standard_1024": 0.040,
              "standard_1792": 0.080,
              "hd_1024": 0.080,
              "hd_1792": 0.120,
              "unit": "per_image"
            },
            "capabilities": ["realistic", "artistic", "detailed", "text-in-image"],
            "styles": ["vivid", "natural"],
            "fallbackPriority": 1,
            "available": true,
            "deprecated": false
          },
          "dall-e-2": {
            "id": "dall-e-2",
            "type": "image",
            "qualityTier": "standard",
            "contextWindow": 1000,
            "supportedSizes": ["256x256", "512x512", "1024x1024"],
            "supportedQualities": ["standard"],
            "pricing": {
              "256": 0.016,
              "512": 0.018,
              "1024": 0.020,
              "unit": "per_image"
            },
            "capabilities": ["artistic", "fast"],
            "fallbackPriority": 2,
            "available": true,
            "deprecated": false
          }
        }
      },
      "together": {
        "name": "Together AI",
        "type": "together",
        "apiBase": "https://api.together.xyz/v1",
        "supportsStyles": true,
        "models": {
          "flux-schnell-free": {
            "id": "black-forest-labs/FLUX.1-schnell-Free",
            "type": "image",
            "qualityTier": "fast",
            "contextWindow": 77,
            "supportedSizes": ["1024x1024", "768x768", "512x512"],
            "supportedQualities": ["standard"],
            "pricing": {
              "perMegapixel": 0.0,
              "default1024": 0.0,
              "unit": "per_megapixel",
              "free": true,
              "defaultSteps": 4
            },
            "capabilities": ["artistic", "very-fast", "free"],
            "fallbackPriority": 1,
            "available": true,
            "deprecated": false,
            "note": "Free tier with rate limit of 10 img/min. Cost = MP × $0.00"
          },
          "flux-schnell": {
            "id": "black-forest-labs/FLUX.1-schnell",
            "type": "image",
            "qualityTier": "standard",
            "contextWindow": 77,
            "supportedSizes": ["1024x1024", "768x768", "512x512"],
            "supportedQualities": ["standard"],
            "pricing": {
              "perMegapixel": 0.003,
              "default1024": 0.003,
              "unit": "per_megapixel",
              "defaultSteps": 4
            },
            "capabilities": ["artistic", "fast", "quality"],
            "fallbackPriority": 2,
            "available": true,
            "deprecated": false,
            "note": "Turbo version, 4 default steps. Cost = MP × $0.003 × (steps ÷ 4) if steps > 4"
          },
          "flux-dev": {
            "id": "black-forest-labs/FLUX.1-dev",
            "type": "image",
            "qualityTier": "high",
            "contextWindow": 77,
            "supportedSizes": ["1024x1024", "768x1024", "1024x768"],
            "supportedQualities": ["standard"],
            "pricing": {
              "perMegapixel": 0.025,
              "default1024": 0.025,
              "unit": "per_megapixel",
              "defaultSteps": 28
            },
            "capabilities": ["artistic", "detailed", "high-quality"],
            "fallbackPriority": 3,
            "available": true,
            "deprecated": false,
            "note": "Dev version, 28 default steps. Cost = MP × $0.025 × (steps ÷ 28) if steps > 28"
          },
          "stable-diffusion-xl": {
            "id": "stabilityai/stable-diffusion-xl-base-1.0",
            "type": "image",
            "qualityTier": "standard",
            "contextWindow": 77,
            "supportedSizes": ["1024x1024", "768x768", "512x512"],
            "supportedQualities": ["standard"],
            "pricing": {
              "default": 0.002,
              "unit": "per_image"
            },
            "capabilities": ["artistic", "fast", "stylized"],
            "fallbackPriority": 99,
            "available": false,
            "deprecated": true,
            "note": "Requires dedicated endpoint, not available on serverless"
          },
          "stable-diffusion-2-1": {
            "id": "stabilityai/stable-diffusion-2-1",
            "type": "image",
            "qualityTier": "fast",
            "contextWindow": 77,
            "supportedSizes": ["768x768", "512x512"],
            "supportedQualities": ["standard"],
            "pricing": {
              "default": 0.001,
              "unit": "per_image"
            },
            "capabilities": ["artistic", "very-fast"],
            "fallbackPriority": 99,
            "available": false,
            "deprecated": true,
            "note": "Requires dedicated endpoint, not available on serverless"
          },
          "playground-v2-5": {
            "id": "playgroundai/playground-v2.5-1024px-aesthetic",
            "type": "image",
            "qualityTier": "high",
            "contextWindow": 77,
            "supportedSizes": ["1024x1024", "768x768"],
            "supportedQualities": ["standard"],
            "pricing": {
              "default": 0.003,
              "unit": "per_image"
            },
            "capabilities": ["artistic", "aesthetic", "detailed"],
            "fallbackPriority": 99,
            "available": false,
            "deprecated": true,
            "note": "Requires dedicated endpoint, not available on serverless"
          }
        }
      },
      "replicate": {
        "name": "Replicate",
        "type": "replicate",
        "apiBase": "https://api.replicate.com/v1",
        "supportsStyles": true,
        "models": {
          "sdxl": {
            "id": "stability-ai/sdxl:latest",
            "type": "image",
            "qualityTier": "standard",
            "contextWindow": 77,
            "supportedSizes": ["1024x1024", "768x1024", "1024x768"],
            "supportedQualities": ["standard"],
            "pricing": {
              "default": 0.0025,
              "unit": "per_image"
            },
            "capabilities": ["artistic", "fast", "customizable"],
            "fallbackPriority": 2,
            "available": true,
            "deprecated": false
          },
          "realistic-vision": {
            "id": "saidachmiz/realistic-vision-v5-1:latest",
            "type": "image",
            "qualityTier": "high",
            "contextWindow": 77,
            "supportedSizes": ["512x512", "768x768"],
            "supportedQualities": ["standard"],
            "pricing": {
              "default": 0.0018,
              "unit": "per_image"
            },
            "capabilities": ["photorealistic", "detailed"],
            "fallbackPriority": 4,
            "available": true,
            "deprecated": false
          },
          "flux-kontext-dev": {
            "id": "black-forest-labs/flux-kontext-dev",
            "type": "image-edit",
            "qualityTier": "high",
            "contextWindow": 77,
            "supportedSizes": ["match_input", "1:1", "16:9", "9:16", "4:3", "3:4"],
            "supportedQualities": ["standard"],
            "pricing": {
              "default": 0.025,
              "unit": "per_image"
            },
            "capabilities": ["image-editing", "preservation", "style-transfer", "object-modification"],
            "fallbackPriority": 1,
            "available": true,
            "deprecated": false,
            "description": "Open-weight FLUX Kontext for image editing - $0.025/image, excellent preservation"
          },
          "flux-kontext-pro": {
            "id": "black-forest-labs/flux-kontext-pro",
            "type": "image-edit",
            "qualityTier": "ultra",
            "contextWindow": 77,
            "supportedSizes": ["match_input", "1:1", "16:9", "9:16", "4:3", "3:4"],
            "supportedQualities": ["standard", "high"],
            "pricing": {
              "default": 0.04,
              "unit": "per_image"
            },
            "capabilities": ["image-editing", "preservation", "typography", "precise-edits"],
            "fallbackPriority": 2,
            "available": true,
            "deprecated": false,
            "description": "State-of-the-art image editing - $0.04/image, best prompt following"
          },
          "flux-kontext-max": {
            "id": "black-forest-labs/flux-kontext-max",
            "type": "image-edit",
            "qualityTier": "ultra",
            "contextWindow": 77,
            "supportedSizes": ["match_input", "1:1", "16:9", "9:16", "4:3", "3:4"],
            "supportedQualities": ["premium"],
            "pricing": {
              "default": 0.06,
              "unit": "per_image",
              "estimate": true
            },
            "capabilities": ["image-editing", "preservation", "typography", "premium-quality"],
            "fallbackPriority": 3,
            "available": true,
            "deprecated": false,
            "description": "Premium FLUX Kontext - maximum performance and typography"
          },
          "nano-banana": {
            "id": "google/nano-banana",
            "type": "image-edit",
            "qualityTier": "ultra",
            "contextWindow": 77,
            "supportedSizes": ["match_input", "1:1", "16:9", "9:16"],
            "supportedQualities": ["standard"],
            "pricing": {
              "default": 0.05,
              "unit": "per_image",
              "estimate": true
            },
            "capabilities": ["image-editing", "multi-image", "fast", "preservation"],
            "fallbackPriority": 4,
            "available": true,
            "deprecated": false,
            "description": "Google Gemini 2.5 image editing - fast with multi-image support"
          },
          "seedream-4": {
            "id": "bytedance/seedream-4",
            "type": "image-edit",
            "qualityTier": "ultra",
            "contextWindow": 77,
            "supportedSizes": ["match_input", "4K"],
            "supportedQualities": ["4K", "high"],
            "pricing": {
              "default": 0.08,
              "unit": "per_image",
              "estimate": true
            },
            "capabilities": ["image-editing", "4k-resolution", "precise-edits"],
            "fallbackPriority": 5,
            "available": true,
            "deprecated": false,
            "description": "ByteDance SeeDream-4 - up to 4K resolution image editing"
          },
          "seededit-3": {
            "id": "bytedance/seededit-3.0",
            "type": "image-edit",
            "qualityTier": "high",
            "contextWindow": 77,
            "supportedSizes": ["match_input"],
            "supportedQualities": ["standard"],
            "pricing": {
              "default": 0.03,
              "unit": "per_image",
              "estimate": true
            },
            "capabilities": ["image-editing", "preservation", "lighting", "object-removal"],
            "fallbackPriority": 6,
            "available": true,
            "deprecated": false,
            "description": "Text-guided editing with preservation of original details"
          }
        }
      }
    },
    "qualityTiers": {
      "ultra": {
        "description": "Highest quality, photorealistic images",
        "keywords": ["photorealistic", "ultra", "4k", "professional", "highest quality"],
        "recommendedModels": ["gemini:imagen-3", "openai:dall-e-3:hd"],
        "typicalCost": 0.12
      },
      "high": {
        "description": "High quality, detailed artistic or realistic images",
        "keywords": ["high quality", "detailed", "artistic", "realistic"],
        "recommendedModels": ["openai:dall-e-3", "together:flux-dev"],
        "typicalCost": 0.04
      },
      "standard": {
        "description": "Good quality, balanced cost/performance",
        "keywords": ["standard", "normal", "regular", "illustration"],
        "recommendedModels": ["together:flux-schnell", "openai:dall-e-2", "replicate:sdxl"],
        "typicalCost": 0.003
      },
      "fast": {
        "description": "Fast generation, lower cost",
        "keywords": ["fast", "quick", "draft", "sketch", "simple"],
        "recommendedModels": ["together:flux-schnell-free", "together:flux-schnell", "openai:dall-e-2"],
        "typicalCost": 0.0
      }
    }
  }
}