{
  "version": "1.0.0",
  "lastUpdated": "2025-10-09",
  "chat": {
    "description": "Chat/completion LLM providers",
    "providers": {
      "groq-free": {
        "name": "Groq Free Tier",
        "type": "groq-free",
        "apiBase": "https://api.groq.com/openai/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": true,
          "limits": {
            "requestsPerMinute": 7000,
            "requestsPerDay": 14400,
            "tokensPerMinute": 30000,
            "tokensPerDay": null
          }
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "llama-3.1-8b-instant": {
            "id": "llama-3.1-8b-instant",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 30000,
              "requestsPerMinute": 7000
            },
            "deprecated": false,
            "available": true
          }
        }
      },
      "groq": {
        "name": "Groq Paid",
        "type": "groq",
        "apiBase": "https://api.groq.com/openai/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": false
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "llama-3.1-8b-instant": {
            "id": "llama-3.1-8b-instant",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.05,
              "output": 0.08,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 30000,
              "requestsPerMinute": 7000
            },
            "deprecated": false,
            "available": true
          },
          "meta-llama/llama-4-scout-17b-16e-instruct": {
            "id": "meta-llama/llama-4-scout-17b-16e-instruct",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 32768,
            "pricing": {
              "input": 0.1,
              "output": 0.15,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 30000,
              "requestsPerMinute": 7000
            },
            "deprecated": false,
            "available": true
          },
          "llama-3.3-70b-versatile": {
            "id": "llama-3.3-70b-versatile",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 32768,
            "pricing": {
              "input": 0.59,
              "output": 0.79,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 6000,
              "requestsPerMinute": 30
            },
            "deprecated": false,
            "available": true
          },
          "mixtral-8x7b-32768": {
            "id": "mixtral-8x7b-32768",
            "category": "large",
            "contextWindow": 32768,
            "maxOutput": 32768,
            "pricing": {
              "input": 0.24,
              "output": 0.24,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 5000,
              "requestsPerMinute": 30
            },
            "deprecated": false,
            "available": true
          },
          "openai/gpt-oss-120b": {
            "id": "openai/gpt-oss-120b",
            "category": "reasoning",
            "contextWindow": 131072,
            "maxOutput": 65536,
            "pricing": {
              "input": 0.5,
              "output": 0.5,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 7000,
              "requestsPerMinute": 30
            },
            "deprecated": false,
            "available": true
          }
        }
      },
      "openai": {
        "name": "OpenAI",
        "type": "openai",
        "apiBase": "https://api.openai.com/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "supportsVision": true,
        "freeTier": {
          "available": false
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "gpt-4o-mini": {
            "id": "gpt-4o-mini",
            "category": "small",
            "contextWindow": 128000,
            "maxOutput": 16384,
            "pricing": {
              "input": 0.15,
              "output": 0.6,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 2000000,
              "requestsPerMinute": 10000
            },
            "deprecated": false,
            "available": true
          },
          "gpt-4o": {
            "id": "gpt-4o",
            "category": "large",
            "contextWindow": 128000,
            "maxOutput": 16384,
            "pricing": {
              "input": 2.5,
              "output": 10,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 800000,
              "requestsPerMinute": 10000
            },
            "deprecated": false,
            "available": true
          },
          "o1-preview": {
            "id": "o1-preview",
            "category": "reasoning",
            "contextWindow": 128000,
            "maxOutput": 32768,
            "pricing": {
              "input": 15,
              "output": 60,
              "unit": "per_million_tokens"
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": false,
            "rateLimits": {
              "tokensPerMinute": 40000,
              "requestsPerMinute": 500
            },
            "deprecated": false,
            "available": true
          },
          "o1-mini": {
            "id": "o1-mini",
            "category": "reasoning",
            "contextWindow": 128000,
            "maxOutput": 65536,
            "pricing": {
              "input": 3,
              "output": 12,
              "unit": "per_million_tokens"
            },
            "supportsTools": false,
            "supportsVision": false,
            "supportsStreaming": false,
            "rateLimits": {
              "tokensPerMinute": 200000,
              "requestsPerMinute": 500
            },
            "capabilities": [
              "chat",
              "reasoning"
            ],
            "deprecated": false,
            "available": true
          }
        }
      },
      "gemini-free": {
        "name": "Google Gemini Free Tier",
        "type": "gemini-free",
        "apiBase": "https://generativelanguage.googleapis.com/v1beta",
        "supportsStreaming": true,
        "supportsTools": true,
        "supportsVision": true,
        "freeTier": {
          "available": true,
          "limits": {
            "requestsPerMinute": 15,
            "requestsPerDay": 1500,
            "tokensPerMinute": 32000,
            "tokensPerDay": 50000000
          }
        },
        "rateLimitHeaders": {
          "format": "custom",
          "note": "May not expose all limits in headers"
        },
        "models": {
          "gemini-1.5-flash": {
            "id": "gemini-1.5-flash",
            "category": "small",
            "contextWindow": 1000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 1500
            },
            "deprecated": false,
            "available": true
          },
          "gemini-1.5-pro": {
            "id": "gemini-1.5-pro",
            "category": "large",
            "contextWindow": 2000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 360
            },
            "deprecated": false,
            "available": true
          },
          "gemini-2.0-flash-exp": {
            "id": "gemini-2.0-flash-exp",
            "category": "large",
            "contextWindow": 1000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 10
            },
            "deprecated": false,
            "available": true
          }
        }
      },
      "gemini": {
        "name": "Google Gemini Paid",
        "type": "gemini",
        "apiBase": "https://generativelanguage.googleapis.com/v1beta",
        "supportsStreaming": true,
        "supportsTools": true,
        "supportsVision": true,
        "freeTier": {
          "available": false
        },
        "rateLimitHeaders": {
          "format": "custom",
          "note": "May not expose all limits in headers"
        },
        "models": {
          "gemini-1.5-flash": {
            "id": "gemini-1.5-flash",
            "category": "small",
            "contextWindow": 1000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true,
              "paidInput": 0.075,
              "paidOutput": 0.3
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 1500
            },
            "deprecated": false,
            "available": true
          },
          "gemini-1.5-pro": {
            "id": "gemini-1.5-pro",
            "category": "large",
            "contextWindow": 2000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true,
              "paidInput": 1.25,
              "paidOutput": 5
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 360
            },
            "deprecated": false,
            "available": true
          },
          "gemini-2.0-flash-exp": {
            "id": "gemini-2.0-flash-exp",
            "category": "large",
            "contextWindow": 1000000,
            "maxOutput": 8192,
            "pricing": {
              "input": 0,
              "output": 0,
              "unit": "per_million_tokens",
              "free": true
            },
            "supportsTools": true,
            "supportsVision": true,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 4000000,
              "requestsPerMinute": 10
            },
            "deprecated": false,
            "available": true
          }
        }
      },
      "together": {
        "name": "Together AI",
        "type": "together",
        "apiBase": "https://api.together.xyz/v1",
        "supportsStreaming": true,
        "supportsTools": true,
        "freeTier": {
          "available": true,
          "limits": {
            "note": "$25 free trial credits available"
          }
        },
        "rateLimitHeaders": {
          "format": "standard",
          "prefix": "x-ratelimit-"
        },
        "models": {
          "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
            "id": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "category": "large",
            "contextWindow": 131072,
            "maxOutput": 4096,
            "pricing": {
              "input": 0.88,
              "output": 0.88,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
            "id": "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
            "category": "small",
            "contextWindow": 131072,
            "maxOutput": 4096,
            "pricing": {
              "input": 0.18,
              "output": 0.18,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          },
          "mistralai/Mixtral-8x7B-Instruct-v0.1": {
            "id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
            "category": "large",
            "contextWindow": 32768,
            "maxOutput": 8192,
            "pricing": {
              "input": 0.6,
              "output": 0.6,
              "unit": "per_million_tokens"
            },
            "supportsTools": true,
            "supportsVision": false,
            "supportsStreaming": true,
            "rateLimits": {
              "tokensPerMinute": 100000,
              "requestsPerMinute": 600
            },
            "deprecated": false,
            "available": true
          }
        }
      }
    }
  },
  "whisper": {
    "description": "Speech-to-text transcription models",
    "providers": {
      "openai": {
        "name": "OpenAI Whisper",
        "available": true,
        "apiBase": "https://api.openai.com/v1",
        "endpoint": "/audio/transcriptions",
        "models": {
          "whisper-1": {
            "id": "whisper-1",
            "pricing": {
              "perMinute": 0.006,
              "unit": "per_minute"
            },
            "maxFileSize": "25MB",
            "supportedFormats": [
              "mp3",
              "mp4",
              "mpeg",
              "mpga",
              "m4a",
              "wav",
              "webm"
            ],
            "supportsTimestamps": true,
            "supportsTranslation": true
          }
        }
      },
      "groq": {
        "name": "Groq Whisper",
        "available": true,
        "apiBase": "https://api.groq.com/openai/v1",
        "endpoint": "/audio/transcriptions",
        "models": {
          "whisper-large-v3": {
            "id": "whisper-large-v3",
            "pricing": {
              "perMinute": 0,
              "unit": "per_minute",
              "free": true
            },
            "maxFileSize": "25MB",
            "supportedFormats": [
              "mp3",
              "mp4",
              "mpeg",
              "mpga",
              "m4a",
              "wav",
              "webm"
            ],
            "supportsTimestamps": true,
            "supportsTranslation": false,
            "rateLimits": {
              "requestsPerMinute": 20,
              "requestsPerDay": 1000
            }
          }
        }
      }
    }
  },
  "imageGeneration": {
    "description": "Text-to-image generation models",
    "providers": {
      "openai": {
        "name": "OpenAI DALL-E",
        "available": true,
        "apiBase": "https://api.openai.com/v1",
        "endpoint": "/images/generations",
        "models": {
          "dall-e-3": {
            "id": "dall-e-3",
            "pricing": {
              "standard": {
                "1024x1024": 0.04,
                "1024x1792": 0.08,
                "1792x1024": 0.08
              },
              "hd": {
                "1024x1024": 0.08,
                "1024x1792": 0.12,
                "1792x1024": 0.12
              },
              "unit": "per_image"
            },
            "supportedSizes": [
              "1024x1024",
              "1024x1792",
              "1792x1024"
            ],
            "quality": [
              "standard",
              "hd"
            ],
            "style": [
              "vivid",
              "natural"
            ]
          },
          "dall-e-2": {
            "id": "dall-e-2",
            "pricing": {
              "1024x1024": 0.02,
              "512x512": 0.018,
              "256x256": 0.016,
              "unit": "per_image"
            },
            "supportedSizes": [
              "1024x1024",
              "512x512",
              "256x256"
            ]
          }
        }
      },
      "together": {
        "name": "Together AI Image Models",
        "available": true,
        "apiBase": "https://api.together.xyz/v1",
        "endpoint": "/images/generations",
        "models": {
          "stabilityai/stable-diffusion-xl-base-1.0": {
            "id": "stabilityai/stable-diffusion-xl-base-1.0",
            "pricing": {
              "perImage": 0.002,
              "unit": "per_image"
            },
            "supportedSizes": [
              "1024x1024",
              "512x512",
              "768x768"
            ],
            "steps": {
              "min": 1,
              "max": 100,
              "default": 20
            }
          },
          "runwayml/stable-diffusion-v1-5": {
            "id": "runwayml/stable-diffusion-v1-5",
            "pricing": {
              "perImage": 0.001,
              "unit": "per_image"
            },
            "supportedSizes": [
              "512x512",
              "768x768"
            ],
            "steps": {
              "min": 1,
              "max": 100,
              "default": 20
            }
          }
        }
      }
    }
  },
  "openaiCompatibleEndpoints": [
    {
      "name": "Anyscale Endpoints",
      "endpoint": "https://api.endpoints.anyscale.com/v1",
      "description": "Ray-powered serverless LLM inference",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "Anyscale Endpoints",
      "endpoint": "https://api.endpoints.anyscale.com/v1",
      "description": "Ray-powered serverless LLM inference",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "Perplexity AI",
      "endpoint": "https://api.perplexity.ai",
      "description": "Search-augmented language models",
      "supported": [
        "chat",
        "streaming"
      ]
    },
    {
      "name": "DeepInfra",
      "endpoint": "https://api.deepinfra.com/v1/openai",
      "description": "Fast inference for popular models",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "Fireworks AI",
      "endpoint": "https://api.fireworks.ai/inference/v1",
      "description": "Production-ready LLM platform",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    },
    {
      "name": "Ollama (Local)",
      "endpoint": "http://localhost:11434/v1",
      "description": "Run models locally on your machine",
      "supported": [
        "chat",
        "streaming"
      ]
    },
    {
      "name": "LocalAI (Local)",
      "endpoint": "http://localhost:8080/v1",
      "description": "Local OpenAI-compatible API",
      "supported": [
        "chat",
        "tools",
        "streaming"
      ]
    }
  ],
  "modelCategories": {
    "small": {
      "description": "Fast, cost-effective models for simple tasks",
      "useCases": [
        "summarization",
        "quick responses",
        "simple queries"
      ],
      "maxCost": 0.5
    },
    "large": {
      "description": "General-purpose models for most tasks",
      "useCases": [
        "chat",
        "complex queries",
        "tool usage"
      ],
      "maxCost": 5
    },
    "reasoning": {
      "description": "Optimized for multi-step reasoning and analysis",
      "useCases": [
        "planning",
        "analysis",
        "complex problem solving"
      ],
      "maxCost": 20
    }
  }
}